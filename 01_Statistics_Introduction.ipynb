{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistics** is the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data. **Data** are characteristics or information, usually numerical, that are collected through observation. In a more technical sense, data are a set of values of qualitative or quantitative variables about one or more persons or objects.\n",
    "\n",
    "Two main statistical methods are used in data analysis: **descriptive statistics**, which summarize data from a sample using indexes such as the mean or standard deviation, and **inferential statistics**, which draw conclusions from data that are subject to random variation.\n",
    "\n",
    "*wiki - Statistics*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive vs Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriptive statistics** describe a sample. You simply take a group that you’re interested in, record data about the group members, and then use summary statistics and graphs to present the group properties. With descriptive statistics, there is no uncertainty because you are describing only the people or items that you actually measure. You’re not trying to infer properties about a larger population.\\\n",
    "Descriptive satistics is solely concerned with properties of the observed data, and it does not rest on the assumption that the data come from a larger population.\n",
    "\n",
    "Descriptive statistics frequently use the following statistical measures to describe groups:\n",
    "- Central tendency: Use the mean or the median to locate the center of the dataset. This measure tells you where most values fall.\n",
    "- Dispersion: How far out from the center do the data extend? You can use the range or standard deviation to measure the dispersion.\n",
    "- Skewness: The measure tells you whether the distribution of values is symmetric or skewed.\n",
    "- Relationships of paired data using correlation and scatterplots.\n",
    "\n",
    "**Inferential statistics** - Statistical inference is the process of using data analysis to deduce properties of an underlying distribution of probability. Inferential statistics takes data from a sample and makes inferences about the larger population from which the sample was drawn. It is assumed that the observed data set is sampled from a larger population.\n",
    "\n",
    "Because the goal of inferential statistics is to draw conclusions from a sample and generalize them to a population, we need to have confidence that our sample accurately reflects the population. This requirement affects our process. At a broad level, we must do the following:\n",
    "\n",
    "- Define the population we are studying.\n",
    "- Draw a representative sample from that population.\n",
    "- Use analyses that incorporate the sampling error.\n",
    "\n",
    "Random sampling allows us to have confidence that the sample represents the population. With this method, all items in the population have an equal probability of being selected. This process is a primary method for obtaining samples that mirrors the population on average. Random sampling produces statistics, such as the mean, that do not tend to be too high or too low. Using a random sample, we can generalize from the sample to the broader population. Unfortunately, gathering a truly random sample can be a complicated process.\n",
    "\n",
    "*https://statisticsbyjim.com/basics/descriptive-inferential-statistics/* \\\n",
    "*https://statisticsbyjim.com/basics/populations-parameters-samples-inferential-statistics/* \\\n",
    "*wiki -- Statistical Inference*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main goals of inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In inferential statistics, we try to **infer something about a population from data coming from a sample taken from it**. But what exactly is it that we’re trying to infer? All methods in inferential statistics aim to achieve one of the following goals:\n",
    "\n",
    "- **Parameter estimation**: In the context of probability distributions, a parameter is some (often unknown) constant that determines the properties of the distribution. For example, the parameters of a normal distribution are its mean and its standard deviation. The mean determines the value around which the “bell curve” is centered and the standard deviation determines its width. So, if you know that the data has a normal distribution, parameter estimation would amount to trying to learn the true values of its mean and standard deviation.\n",
    "\n",
    "\n",
    "- **Data prediction**: For this goal, you usually need to already have estimated certain parameters. Then you use them to predict future data. For example, after measuring the heights of females in a sample, you can estimate the mean and standard deviation of the distribution for all adult females. Then you can use these values to predict the probability of a randomly chosen female to have a height within a certain range of values.\n",
    "\n",
    "\n",
    "- **Model comparison**: In short, model comparison is the process of selecting a statistical model from 2 or more models, which best explains the observed data. A model is basically a set of postulates about the process that generates the data.\n",
    "\n",
    "\n",
    "- **Comparing two or more populations** (added by me)\n",
    "\n",
    "https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Philosophies in inferential statistics: frequentist vs Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two general **“philosophies” in inferential statistics are frequentist inference and Bayesian inference**.\n",
    "\n",
    "The difference between frequentist and Bayesian approaches has its roots in the different ways the two define the concept of probability. Frequentist statistics only treats random events probabilistically and doesn’t quantify the uncertainty in fixed but unknown values (such as the uncertainty in the true values of parameters). Bayesian statistics, on the other hand, defines probability distributions over possible values of a parameter which can then be used for other purposes.\n",
    "\n",
    "According to the **frequentist** definition of probability, only repeatable random events (like the result of flipping a coin) have probabilities. These probabilities are equal to the long-term frequency of occurrence of the events in question.\\\n",
    "Frequentists don’t attach probabilities to hypotheses or to any fixed but unknown values in general. This is a very important point that you should carefully examine. Ignoring it often leads to misinterpretations of frequentist analyses.\n",
    "\n",
    "In contrast, **Bayesians** view probabilities as a more general concept. As a Bayesian, you can use probabilities to represent the uncertainty in any event or hypothesis.\n",
    "\n",
    "\n",
    "**Parameter Estimation** \n",
    "\n",
    "Consider the following example. We want to estimate the average height of adult females. First, we assume that height has a normal distribution. Second, we assume that the standard deviation is available and we don’t need to estimate it. Therefore, the only thing we need to estimate is the mean of the distribution.\n",
    "\n",
    "<ins>Frequentists:</ins> they would reason as follows: \"I don’t know what the mean female height is. However, I know that its value is fixed (not a random one). Therefore, I cannot assign probabilities to the mean being equal to a certain value, or being less/greater than some other value. The most I can do is collect data from a sample of the population and estimate its mean as the value which is most consistent with the data.\" The value mentioned in the end is known as the maximum likelihood estimate. For normally distributed data, it’s quite straightforward: the maximum likelihood estimate of the population mean is equal to the sample mean.\n",
    "\n",
    "<ins>Bayesians:</ins> they would reason differently: \"I agree that the mean is a fixed and unknown value, but I see no problem in representing the uncertainty probabilistically. I will do so by defining a probability distribution over the possible values of the mean and use sample data to update this distribution.\"\n",
    "In a Bayesian setting, the newly collected data makes the probability distribution over the parameter narrower. More specifically, narrower around the parameter’s true (unknown) value.\n",
    "\n",
    "Note, when you do parameter estimation, you do it in the context of some more basic assumptions. In this case, the assumption was that of the normal distribution.\n",
    "\n",
    "**Data Prediction**\n",
    "\n",
    "Here, the difference between frequentist and Bayesian approaches is analogous to their difference in parameter estimation. \n",
    "\n",
    "<ins>Frequentists:</ins> they don't assign probabilities to possible parameter values and they use (maximum likelihood) point estimates of unknown parameters to predict new data points.\n",
    "\n",
    "<ins>Bayesians:</ins> they will have a full posterior distribution over the possible parameter values which allows them to take into account the uncertainty in the estimate by integrating the full posterior distribution, instead of basing the prediction just on the most likely value.\n",
    "\n",
    "**Model Comparison**\n",
    "\n",
    "In parameter estimation, you consider how good of a candidate each possible value of the parameter is to fit the data, right? Bayesians would construct a probability distribution over the parameter space, whereas frequentists would calculate a point estimate (MLE).\n",
    "\n",
    "Now, in model comparison, <ins>Bayesians</ins> would instead build a probability distribution over the model space. If there are only 2 candidate models, you would calculate the probability of each model, given the data, in a Bayesian way (by having some prior distribution over the models). Then there are different ways to select the best model based on those probabilities.\n",
    "\n",
    "On the other hand, <ins>Frequentists</ins> will not bother trying to assign probabilities to the different models because in this framework probabilities apply only to data, not to things like parameters or models. One naive approach to frequentist model selection would be to directly compare the MLEs of the two models. Whichever model gives the highest maximum likelihood, it is to be selected. But with that approach you would quickly hit one of the most serious problems in the field: that of overfitting. There are more sophisticated methods that frequentists would use to do model comparison, like cross-validation and likelihood-ratio test.\n",
    "\n",
    "https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics/ \\\n",
    "https://www.probabilisticworld.com/what-is-probability/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with uncertainties: frequentist vs Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesians** can use probabilities to represent the uncertainty in parameters.\n",
    "\n",
    "**Frequentists** don’t treat the uncertainty in the true parameter value probabilistically. However, that doesn’t magically eliminate uncertainty. So the maximum likelihood estimate could still be wrong and, in fact, most of the time it is wrong! When you assume that a particular estimate is the correct one, but in reality it isn’t, you will make an error. Consequently, this has lead to the development of two mathematical techniques for quantifying and limiting long-term error rates:\n",
    "Every time you take a different sample, you might get a different estimate.\n",
    "\n",
    "- **null hypothesis significance testing (NHST)** and the related concept of **p-values**\n",
    "- **confidence intervals**\n",
    "\n",
    "In the absence of probabilistic treatment of parameters, frequentists handle uncertainty by limiting the long-term error rates, either by comparing the estimated parameter against a null value (NHST), or by calculating confidence intervals.\n",
    " \n",
    "https://www.probabilisticworld.com/frequentist-bayesian-approaches-inferential-statistics/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
